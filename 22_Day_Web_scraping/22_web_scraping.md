<div align="center">
  <h1> 30 GÃ¼nde Python: 22. GÃ¼n - Web Scraping </h1>
  <a class="header-badge" target="_blank" href="https://www.linkedin.com/in/asabeneh/">
  <img src="https://img.shields.io/badge/style--5eba00.svg?label=LinkedIn&logo=linkedin&style=social">
  </a>
  <a class="header-badge" target="_blank" href="https://twitter.com/Asabeneh">
  <img alt="Twitter Follow" src="https://img.shields.io/twitter/follow/asabeneh?style=social">
  </a>

<sub>Yazar:
<a href="https://www.linkedin.com/in/asabeneh/" target="_blank">Asabeneh Yetayeh</a><br>
<small> Ä°kinci Versiyon: Temmuz, 2021</small>
</sub>
</div>

[<< 21. GÃ¼n](../21_Day_Classes_and_objects/21_classes_and_objects.md) | [23. GÃ¼n >>](../23_Day_Virtual_environment/23_virtual_environment.md)

![30DaysOfPython](../images/30DaysOfPython_banner3@2x.png)

- [ğŸ“˜ 22. GÃ¼n](#-day-22)
  - [Python Web Scraping](#python-web-scraping)
    - [Web Scrapping Nedir?](#what-is-web-scrapping)
  - [ğŸ’» AlÄ±ÅŸtÄ±rmalar: 22. GÃ¼n](#-exercises-day-22)

# ğŸ“˜ 22. GÃ¼n

## Python Web Scraping

### Web Scrapping Nedir?

Ä°nternet, farklÄ± amaÃ§lar iÃ§in kullanÄ±labilecek bÃ¼yÃ¼k miktarda veriyle doludur. Bu verileri toplamak iÃ§in, bir web sitesinden veri kazÄ±manÄ±n (scraping) nasÄ±l yapÄ±ldÄ±ÄŸÄ±nÄ± bilmemiz gerekir.

Web scraping, web sitelerinden veri Ã§Ä±karma ve toplama, ardÄ±ndan bu verileri yerel makineye veya bir veri tabanÄ±na kaydetme iÅŸlemidir.

Bu bÃ¶lÃ¼mde, scraping iÃ§in BeautifulSoup ve requests paketlerini kullanacaÄŸÄ±z. KullandÄ±ÄŸÄ±mÄ±z BeautifulSoup sÃ¼rÃ¼mÃ¼ BeautifulSoup 4â€™tÃ¼r.

Web sitelerinden veri kazÄ±maya baÅŸlamak iÃ§in _requests_, _BeautifulSoup4_ ve bir _web sitesi_ gereklidir.

```sh
pip install requests
pip install beautifulsoup4
```

Web sitelerinden veri kazÄ±mak iÃ§in, HTML tagleri ve CSS selectorlarÄ± hakkÄ±nda temel bir anlayÄ±ÅŸa sahip olmak gerekir. Bir web sitesindeki iÃ§eriÄŸi hedeflemek iÃ§in HTML taglerini, classlarÄ± ve/veya idleri kullanÄ±rÄ±z.
Åimdi requests ve BeautifulSoup modÃ¼llerini iÃ§e aktaralÄ±m.

```py
import requests
from bs4 import BeautifulSoup
```

Scraping iÅŸlemini yapacaÄŸÄ±mÄ±z web sitesi iÃ§in bir url deÄŸiÅŸkeni tanÄ±mlayalÄ±m.

```py

import requests
from bs4 import BeautifulSoup
url = 'https://archive.ics.uci.edu/ml/datasets.php'

# urlden veri Ã§ekmek iÃ§in requests get metodunu kullanalÄ±m

response = requests.get(url)
# baÅŸarÄ± statusÃ¼nÃ¼ kontrol edelim
status = response.status_code
print(status) # 200 baÅŸarÄ±lÄ± demek
```

```sh
200
```

Sayfadaki iÃ§eriÄŸi BeautifulSoup kullanarak parse etme iÅŸlemini yapalÄ±m.

```py
import requests
from bs4 import BeautifulSoup
url = 'https://archive.ics.uci.edu/ml/datasets.php'

response = requests.get(url)
content = response.content # sitedeki tÃ¼m iÃ§eriÄŸi alma
soup = BeautifulSoup(content, 'html.parser') # beautiful soup parse etmeyi saÄŸlayacak
print(soup.title) # <title>UCI Machine Learning Repository: Data Sets</title>
print(soup.title.get_text()) # UCI Machine Learning Repository: Data Sets
print(soup.body) # tÃ¼m sayfayÄ± verir
print(response.status_code)

tables = soup.find_all('table', {'cellpadding':'3'})
# HÃ¼cre aralÄ±ÄŸÄ± (cellpadding) Ã¶zelliÄŸi 3 olan tabloyu hedefliyoruz.
# SeÃ§imi id, class veya HTML tagi kullanarak yapabiliriz. Daha fazla bilgi iÃ§in BeautifulSoup dokÃ¼manÄ±na (docs) gÃ¶z atÄ±n.
table = tables[0] # sonuÃ§ list olarak dÃ¶ner, veriyi burdan alÄ±yoruz
for td in table.find('tr').find_all('td'):
    print(td.text)
```

Bu kodu Ã§alÄ±ÅŸtÄ±rÄ±rsan, veri Ã§Ä±karma iÅŸleminin yarÄ±sÄ±nÄ±n tamamlandÄ±ÄŸÄ±nÄ± gÃ¶rebilirsin.
Bu iÅŸlemi kendin devam ettirebilirsin Ã§Ã¼nkÃ¼ bu 1. alÄ±ÅŸtÄ±rmanÄ±n bir parÃ§asÄ±dÄ±r.
Referans olarak [BeautifulSoup belgelerine](https://www.crummy.com/software/BeautifulSoup/bs4/doc/#quick-start) bakabilirsin.

ğŸŒ• Ã‡ok iyisin, gÃ¼n gÃ¼n ilerliyorsun. MÃ¼kemellik yolunda sadece 8 gÃ¼nÃ¼n kaldÄ±. Åimdi beynin ve kaslarÄ±n iÃ§in biraz alÄ±ÅŸtÄ±rma yapalÄ±m.

## ğŸ’» AlÄ±ÅŸtÄ±rmalar: 22. GÃ¼n

1. Bu web sitesinden veriyi kazÄ± ve veriyi JSON dosyasÄ± olarak kaydet: (url = 'http://www.bu.edu/president/boston-university-facts-stats/').
1. Bu URLâ€™deki tabloyu Ã§Ä±kar ve tabloyu JSON dosyasÄ± olarak dÃ¶nÃ¼ÅŸtÃ¼r: (https://archive.ics.uci.edu/ml/datasets.php)
2. ABD baÅŸkanlarÄ±nÄ±n tablosunu kazÄ± ve JSON dosyasÄ± olarak kaydet: (https://en.wikipedia.org/wiki/List_of_presidents_of_the_United_States). Tablo Ã§ok dÃ¼zenli deÄŸil, bu yÃ¼zden kazÄ±ma iÅŸlemi uzun sÃ¼rebilir.

ğŸ‰ TEBRÄ°KLER ! ğŸ‰

[<< 21. GÃ¼n](../21_Day_Web_scraping/21_class_and_object.md) | [23. GÃ¼n >>](../23_Day_Virtual_environment/23_virtual_environment.md)
